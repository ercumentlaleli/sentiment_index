{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894602bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para Politikası Metinleri: Şahinlik/Güvercinlik Analizi ve Kelime Ağı\n",
    "# Gereken kütüphaneler:\n",
    "# !pip install pdfplumber transformers torch nltk pyvis networkx pandas matplotlib scikit-learn \n",
    "\n",
    "\n",
    "import pdfplumber, re, os, string, pandas as pd, networkx as nx\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyvis.network import Network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. PDF'den Metin Çıkarma ---\n",
    "pdf_dir = \"/Users/xxxxxxx/Desktop/python2025/xxxxxxx\"  # PDF klasörünü buraya koyun\n",
    "date_pattern = re.compile(r\"(\\d{1,2}\\s+(Ocak|Şubat|Mart|Nisan|Mayıs|Haziran|Temmuz|Ağustos|Eylül|Ekim|Kasım|Aralık)\\s+\\d{4})\", re.IGNORECASE)\n",
    "\n",
    "data = []\n",
    "for file in tqdm(os.listdir(pdf_dir)):\n",
    "    if not file.endswith(\".pdf\"): continue\n",
    "    file_path = os.path.join(pdf_dir, file)\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\\n\".join(page.extract_text() or \"\" for page in pdf.pages)\n",
    "    date_match = date_pattern.search(text)\n",
    "    date_text = date_match.group(1) if date_match else None\n",
    "    data.append({\"file\": file, \"date\": date_text, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Temizleme ---\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation + \"0123456789\"))\n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "month_map = {\n",
    "    \"ocak\": 1, \"şubat\": 2, \"mart\": 3, \"nisan\": 4, \"mayıs\": 5, \"haziran\": 6,\n",
    "    \"temmuz\": 7, \"ağustos\": 8, \"eylül\": 9, \"ekim\": 10, \"kasım\": 11, \"aralık\": 12\n",
    "}\n",
    "def parse_date(date_str):\n",
    "    if not date_str: return None\n",
    "    parts = date_str.split()\n",
    "    if len(parts) == 3:\n",
    "        day = int(parts[0]); month = month_map.get(parts[1].lower(), None); year = int(parts[2])\n",
    "        if month: return pd.Timestamp(year, month, day)\n",
    "    return None\n",
    "df[\"parsed_date\"] = df[\"date\"].apply(parse_date)\n",
    "df = df.sort_values(by=\"parsed_date\")\n",
    "\n",
    "# --- 3. Sözlük Tabanlı Şahinlik Endeksi ---\n",
    "hawkish_words = [\"sıkılaştırma\",\"faiz artışı\",\"faiz artırımı\",\"enflasyon\",\"enflasyonist\",\"fiyat istikrarı\",\"risk\",\"baskı\",\"sıkı\",\"oynaklık\",\"enflasyon beklentisi\",\"tedbir\",\"önlem\",\"parasal sıkılaştırma\"]\n",
    "dovish_words = [\"gevşeme\",\"faiz indirimi\",\"faiz düşüşü\",\"destekleyici\",\"büyüme\",\"istihdam\",\"toparlanma\",\"kredi genişlemesi\",\"canlandırma\",\"teşvik\",\"parasal genişleme\",\"rehberlik\",\"güven artırıcı\"]\n",
    "def compute_hawkishness(text):\n",
    "    words = text.split()\n",
    "    hawk_count = sum(word in words for word in hawkish_words)\n",
    "    dove_count = sum(word in words for word in dovish_words)\n",
    "    total = hawk_count + dove_count\n",
    "    return hawk_count / total if total > 0 else None\n",
    "df[\"hawkish_score_dict\"] = df[\"clean_text\"].apply(compute_hawkishness)\n",
    "\n",
    "# --- 4. BERTurk ile Şahinlik Skoru (0-1) ---\n",
    "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()[0]\n",
    "\n",
    "hawk_ref = \"Bu metin sıkılaştırıcı bir para politikası tonuna sahiptir.\"\n",
    "dove_ref = \"Bu metin destekleyici ve gevşetici bir para politikası tonuna sahiptir.\"\n",
    "hawk_emb = get_embedding(hawk_ref)\n",
    "dove_emb = get_embedding(dove_ref)\n",
    "\n",
    "bert_scores = []\n",
    "for text in tqdm(df[\"clean_text\"].fillna(\"\").tolist()):\n",
    "    if len(text.strip()) == 0:\n",
    "        bert_scores.append(None); continue\n",
    "    emb = get_embedding(text[:2000])\n",
    "    sim_hawk = cosine_similarity([emb], [hawk_emb])[0][0]\n",
    "    sim_dove = cosine_similarity([emb], [dove_emb])[0][0]\n",
    "    score = sim_hawk / (sim_hawk + sim_dove) if (sim_hawk + sim_dove) > 0 else None\n",
    "    bert_scores.append(score)\n",
    "df[\"hawkish_score_bert\"] = bert_scores\n",
    "\n",
    "# --- 5. Zaman Serisi Çizimi ---\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df[\"parsed_date\"], df[\"hawkish_score_dict\"], label=\"Sözlük Tabanlı\", alpha=0.7)\n",
    "plt.plot(df[\"parsed_date\"], df[\"hawkish_score_bert\"], label=\"BERT Tabanlı\", alpha=0.7)\n",
    "plt.legend(); plt.title(\"Şahinlik Endeksi (Sözlük vs BERT)\"); plt.xlabel(\"Tarih\"); plt.ylabel(\"Endeks\"); plt.show()\n",
    "\n",
    "# --- 6. Kelime Ağı ---\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('turkish'))\n",
    "\n",
    "def get_top_words(texts, top_n=300):\n",
    "    all_words = []\n",
    "    for t in texts:\n",
    "        all_words.extend([w for w in t.split() if w not in stop_words and len(w)>3])\n",
    "    return [w for w,_ in Counter(all_words).most_common(top_n)]\n",
    "\n",
    "top_words = get_top_words(df[\"clean_text\"].tolist(), top_n=300)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
